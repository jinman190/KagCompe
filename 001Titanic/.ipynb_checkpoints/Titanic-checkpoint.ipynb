{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 10,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"input/train.csv\")\n",
    "df_test = pd.read_csv(\"input/test.csv\")\n",
    "\n",
    "#Looking data format and types\n",
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Name\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n",
    "\n",
    "#Plotting the result\n",
    "sns.countplot(x='Title', data=df_train, palette=\"hls\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_Dictionary = {\n",
    "        \"Capt\":       \"Officer\",\n",
    "        \"Col\":        \"Officer\",\n",
    "        \"Major\":      \"Officer\",\n",
    "        \"Dr\":         \"Officer\",\n",
    "        \"Rev\":        \"Officer\",\n",
    "        \"Jonkheer\":   \"Royalty\",\n",
    "        \"Don\":        \"Royalty\",\n",
    "        \"Sir\" :       \"Royalty\",\n",
    "        \"the Countess\":\"Royalty\",\n",
    "        \"Dona\":       \"Royalty\",\n",
    "        \"Lady\" :      \"Royalty\",\n",
    "        \"Mme\":        \"Mrs\",\n",
    "        \"Ms\":         \"Mrs\",\n",
    "        \"Mrs\" :       \"Mrs\",\n",
    "        \"Mlle\":       \"Miss\",\n",
    "        \"Miss\" :      \"Miss\",\n",
    "        \"Mr\" :        \"Mr\",\n",
    "        \"Master\" :    \"Master\"\n",
    "                   }\n",
    "    \n",
    "# we map each title to correct category\n",
    "df_train['Title'] = df_train.Title.map(Title_Dictionary)\n",
    "df_test['Title'] = df_test.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Title', data=df_train, palette=\"hls\",hue=\"Survived\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Pclass', data=df_train, palette=\"hls\",hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked', data=df_train, palette=\"hls\",hue=\"Survived\") #출항지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_high_zero = df_train[df_train[\"Age\"] > 0]\n",
    "\n",
    "sns.distplot(age_high_zero[\"Age\"], bins=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n",
    "\n",
    "print(age_group.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n",
    "df_test.loc[df_test.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n",
    "print(df_train[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex_Dictionary = {\n",
    "        \"male\":     0,\n",
    "        \"female\":    1\n",
    "}\n",
    "    \n",
    "# we map each title to correct category\n",
    "df_train['SexNum'] = df_train.Sex.map(Sex_Dictionary)\n",
    "df_test['SexNum'] = df_test.Sex.map(Sex_Dictionary)\n",
    "\n",
    "Embarked1_Dictionary = {\n",
    "        \"S\":     1,\n",
    "        \"C\":     0,\n",
    "        \"Q\":     0\n",
    "}\n",
    "Embarked2_Dictionary = {\n",
    "        \"S\":     0,\n",
    "        \"C\":     1,\n",
    "        \"Q\":     0\n",
    "}\n",
    "Embarked3_Dictionary = {\n",
    "        \"S\":     0,\n",
    "        \"C\":     0,\n",
    "        \"Q\":    1\n",
    "}\n",
    "    \n",
    "# we map each title to correct category\n",
    "df_train['Embarked1Num'] = df_train.Embarked.map(Embarked1_Dictionary)\n",
    "df_test['Embarked1Num'] = df_test.Embarked.map(Embarked1_Dictionary)\n",
    "df_train['Embarked2Num'] = df_train.Embarked.map(Embarked2_Dictionary)\n",
    "df_test['Embarked2Num'] = df_test.Embarked.map(Embarked2_Dictionary)\n",
    "df_train['Embarked3Num'] = df_train.Embarked.map(Embarked3_Dictionary)\n",
    "df_test['Embarked3Num'] = df_test.Embarked.map(Embarked3_Dictionary)\n",
    "\n",
    "df_train['AgeNorm'] = (df_train['Age'] - df_train['Age'].min()) / (df_train['Age'].max() - df_train['Age'].min())\n",
    "df_test['AgeNorm'] = (df_test['Age'] - df_train['Age'].min()) / (df_train['Age'].max() - df_train['Age'].min())\n",
    "df_train['FareNorm'] = (df_train['Fare'] - df_train['Fare'].min()) / (df_train['Fare'].max() - df_train['Fare'].min())\n",
    "df_test['FareNorm'] = (df_test['Fare'] - df_train['Fare'].min()) / (df_train['Fare'].max() - df_train['Fare'].min())\n",
    "df_train['SibSpNorm'] = (df_train['SibSp'] - df_train['SibSp'].min()) / (df_train['SibSp'].max() - df_train['SibSp'].min())\n",
    "df_test['SibSpNorm'] = (df_test['SibSp'] - df_train['SibSp'].min()) / (df_train['SibSp'].max() - df_train['SibSp'].min())\n",
    "df_train['PclassNorm'] = (df_train['Pclass'] - df_train['Pclass'].min()) / (df_train['Pclass'].max() - df_train['Pclass'].min())\n",
    "df_test['PclassNorm'] = (df_test['Pclass'] - df_train['Pclass'].min()) / (df_train['Pclass'].max() - df_train['Pclass'].min())\n",
    "df_train['ParchNorm'] = (df_train['Parch'] - df_train['Parch'].min()) / (df_train['Parch'].max() - df_train['Parch'].min())\n",
    "df_test['ParchNorm'] = (df_test['Parch'] - df_train['Parch'].min()) / (df_train['Parch'].max() - df_train['Parch'].min())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = df_train[[\"PclassNorm\", \"SexNum\", \"AgeNorm\", \"SibSpNorm\", \"ParchNorm\", \"FareNorm\"]].as_matrix()#, \"Embarked1Num\", \"Embarked2Num\", \"Embarked3Num\"]].as_matrix()\n",
    "y_data = df_train[\"Survived\"].as_matrix()\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "\n",
    "x_datatest = df_test[[\"PclassNorm\", \"SexNum\", \"AgeNorm\", \"SibSpNorm\", \"ParchNorm\", \"FareNorm\"]].as_matrix()#, \"Embarked1Num\", \"Embarked2Num\", \"Embarked3Num\"]].as_matrix()\n",
    "\n",
    "#x_data = [[1,2],[2,3],[3,1], [4,3], [5,3], [6,2]]\n",
    "#y_data = [[0], [0], [0], [1], [1], [1]]#fail 0 pass 1\n",
    "print(x_data[1])\n",
    "#print(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_X = 6\n",
    "hidden = 10\n",
    "Bhidden = 15\n",
    "Chidden = 20\n",
    "nb_classes = 1 #답의 가짓수\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None,column_X], name=\"X\")\n",
    "Y = tf.placeholder(tf.float64, [None,1], name=\"Y\")\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([column_X, hidden], name='weight1', dtype=tf.float64, stddev=0.01), dtype=tf.float64)\n",
    "b1 = tf.Variable(tf.random_normal([hidden], name='bias1', dtype=tf.float64), dtype=tf.float64)\n",
    "W2 = tf.Variable(tf.random_normal([hidden, nb_classes], name='weight2', dtype=tf.float64, stddev=0.01), dtype=tf.float64)\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes], name='bias2', dtype=tf.float64), dtype=tf.float64)\n",
    "\n",
    "hypo1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(hypo1, W2) + b2)\n",
    "Acost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*(tf.log(1-hypothesis)))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(Acost)\n",
    "\n",
    "Aprediction = tf.cast(hypothesis > 0.5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "BW1 = tf.Variable(tf.random_normal([column_X, Bhidden], name='Bweight1', dtype=tf.float64, stddev=0.01), dtype=tf.float64)\n",
    "Bb1 = tf.Variable(tf.random_normal([Bhidden], name='Bbias1', dtype=tf.float64), dtype=tf.float64)\n",
    "BW2 = tf.Variable(tf.random_normal([Bhidden, nb_classes], name='Bweight2', dtype=tf.float64, stddev=0.01), dtype=tf.float64)\n",
    "Bb2 = tf.Variable(tf.random_normal([nb_classes], name='Bbias2', dtype=tf.float64), dtype=tf.float64)\n",
    "\n",
    "Bhypo1 = tf.nn.relu(tf.matmul(X, BW1) + Bb1)\n",
    "Bhypothesis = tf.sigmoid(tf.matmul(Bhypo1, BW2) + Bb2)\n",
    "Bcost = -tf.reduce_mean(Y*tf.log(Bhypothesis) + (1-Y)*(tf.log(1-Bhypothesis)))\n",
    "Boptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(Bcost)\n",
    "\n",
    "Bprediction = tf.cast(Bhypothesis > 0.5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "CW1 = tf.Variable(tf.random_normal([column_X, Chidden], name='Cweight1', dtype=tf.float64), dtype=tf.float64)\n",
    "Cb1 = tf.Variable(tf.random_normal([Chidden], name='Cbias1', dtype=tf.float64), dtype=tf.float64)\n",
    "CW2 = tf.Variable(tf.random_normal([Chidden, nb_classes], name='Cweight2', dtype=tf.float64), dtype=tf.float64)\n",
    "Cb2 = tf.Variable(tf.random_normal([nb_classes], name='Cbias2', dtype=tf.float64), dtype=tf.float64)\n",
    "\n",
    "Chypo1 = tf.nn.relu(tf.matmul(X, CW1) + Cb1)\n",
    "Chypothesis = tf.sigmoid(tf.matmul(Chypo1, CW2) + Cb2)\n",
    "Ccost = -tf.reduce_mean(Y*tf.log(Chypothesis) + (1-Y)*(tf.log(1-Chypothesis)))\n",
    "Coptimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(Ccost)\n",
    "\n",
    "Cprediction = tf.cast(Chypothesis > 0.5, dtype=tf.int32)\n",
    "\n",
    "cost = Acost + Bcost + Ccost\n",
    "#prediction = tf.cast((Aprediction + Bprediction + Cprediction > 1), dtype=tf.int32)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100000):\n",
    "    Acost_val, Bcost_val, Ccost_val, _, _, _ = sess.run([Acost, Bcost, Ccost, optimizer, Boptimizer, Coptimizer], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", Acost_val, \"     \", Bcost_val, \"     \", Ccost_val)\n",
    "    \n",
    "h, a, b, c = sess.run([hypothesis, Aprediction, Bprediction, Cprediction], feed_dict={X: x_datatest})\n",
    "\n",
    "Aoutput = pd.DataFrame(data=a, columns=['a'])\n",
    "Boutput = pd.DataFrame(data=b, columns=['a'])\n",
    "Coutput = pd.DataFrame(data=c, columns=['a'])\n",
    "\n",
    "df_add = Aoutput.add(Boutput)\n",
    "df_add = df_add.add(Coutput)\n",
    "\n",
    "result_Dictionary = {\n",
    "        0:     0,\n",
    "        1:     0,\n",
    "        2:     1,\n",
    "        3:     1\n",
    "}\n",
    "    \n",
    "# we map each title to correct category\n",
    "output = df_add.a.map(result_Dictionary)\n",
    "\n",
    "print(output)\n",
    "df_test[\"Survived\"] = output\n",
    "result = df_test[[\"PassengerId\", \"Survived\"]]\n",
    "#print(result)\n",
    "result.to_csv(\"a.csv\", sep=',', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
